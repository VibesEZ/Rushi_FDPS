{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "random_state = 42\n",
    "n_components_opt = 20\n",
    "best_estimator = 50\n",
    "max_depth_opt = 15\n",
    "best_min_samples_split = 20\n",
    "best_min_samples_leaf = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "df = pd.read_csv(\"data/Airlines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preparation\n",
    "\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "categorical_columns = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "\n",
    "for c in categorical_columns:\n",
    "    df[c] = df[c].str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Delete columns useless for classification\n",
    "del df['id']\n",
    "del df['flight']\n",
    "\n",
    "# Convert data type of day_of_week\n",
    "df['dayofweek'] = df['dayofweek'].astype('object')\n",
    "\n",
    "# Creation of new features\n",
    "# df['airport_mix'] = df['airportfrom'] + ' - ' + df['airportto']\n",
    "\n",
    "target = 'delay'\n",
    "cat = ['airline', 'airportfrom', 'airportto', 'dayofweek'\n",
    "    #    ,'airport_mix'\n",
    "        ]\n",
    "num = ['time', 'length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=random_state)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=random_state)\n",
    "\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "y_full_train = df_full_train[target].values\n",
    "del df_full_train[target]\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "y_train = df_train[target].values\n",
    "del df_train[target]\n",
    "\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "y_val = df_val[target].values\n",
    "del df_val[target]\n",
    "\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "y_test = df_test[target].values\n",
    "del df_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(df_train):\n",
    "    dicts_train = df_train.to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts_train)\n",
    "\n",
    "    return dv,X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv,X_train = vectorize(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_df(df, dv):\n",
    "    '''transform dataframe to matrix and return de X dataframe with respective name as name variable'''\n",
    "    dicts = df.to_dict(orient='records')\n",
    "    df_name = dv.transform(dicts)\n",
    "    return df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val = vectorize_df(df_val, dv)\n",
    "# X_test = vectorize_df(df_test, dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimention_reduction(X_train, n_components):\n",
    "    '''reduce dimention of data using PCA and return the new X_train, X_val, X_test'''\n",
    "    pca = PCA(n_components=n_components, random_state=random_state)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "    return X_train_pca,pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca,pca = dimention_reduction(X_train, n_components_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323629, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323629, 606)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train_pca, y_train, n_estimators, max_depth, min_samples_split, min_samples_leaf):\n",
    "    '''train the model and return the model'''\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, random_state=random_state, n_jobs=-1)\n",
    "    rf.fit(X_train_pca, y_train)\n",
    "    return rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, df, dv, pca):\n",
    "    '''predict the model and return the prediction'''\n",
    "    X = vectorize_df(df, dv)\n",
    "    X_pca = pca.transform(X)\n",
    "    y_pred = model.predict_proba(X_pca)[:, 1]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('-------------------------------------')\n",
    "# print('Train')\n",
    "rf = train(X_train_pca, y_train, best_estimator, max_depth_opt, best_min_samples_split, best_min_samples_leaf)\n",
    "# print('Training completed')\n",
    "# print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('-------------------------------------')\n",
    "# print('Evaluation on validation')\n",
    "y_pred_val = predict(rf, df_val, dv , pca)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "# print('AUC on validation: {:.3f}'.format(auc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('-------------------------------------')\n",
    "# print('Evaluation on test')\n",
    "y_pred_test = predict(rf, df_test, dv , pca)\n",
    "auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "# print('AUC on test: {:.3f}'.format(auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Train with full train data\n",
      "Training completed\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-------------------------------------')\n",
    "print('Train with full train data')\n",
    "\n",
    "dv,X_full_train = vectorize(df_full_train)\n",
    "X_full_train_pca,pca = dimention_reduction(X_full_train, n_components_opt)\n",
    "rf = train(X_full_train_pca, y_full_train, best_estimator, max_depth_opt, best_min_samples_split, best_min_samples_leaf)\n",
    "\n",
    "print('Training completed')\n",
    "print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Evaluation on test\n",
      "AUC on test: 0.722\n"
     ]
    }
   ],
   "source": [
    "print('-------------------------------------')\n",
    "print('Evaluation on test')\n",
    "y_pred_test = predict(rf, df_test, dv , pca)\n",
    "\n",
    "auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "print('AUC on test: {:.3f}'.format(auc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The model is saved to final_model.bin\n"
     ]
    }
   ],
   "source": [
    "# Save model \n",
    "output_file = 'final_model.bin'\n",
    "\n",
    "with open(output_file, 'wb') as f_out: \n",
    "    pickle.dump((dv, pca, rf), f_out)\n",
    "print('\\n')\n",
    "print(f'The model is saved to {output_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
